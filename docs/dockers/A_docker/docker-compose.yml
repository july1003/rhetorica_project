

services:
  # 1. 메시지 브로커
  redis:
    image: redis:7.2-alpine
    container_name: central_redis
    ports:
      - "6379:6379"
    restart: always

  # 2. 메인 웹 서버 (FastAPI)
  web:
    build: .
    container_name: interview_api
    ports:
      - "8000:8000"
    env_file: .env
    environment:
      - PHOENIX_COLLECTOR_ENDPOINT=http://phoenix:6006
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://phoenix:6006
    depends_on:
      - redis
      - phoenix
    volumes:
      - Z:\:/shared_data # 윈도우 Z드라이브를 컨테이너 내 /shared_data로 매핑
      - ../../../:/app # 프로젝트 루트를 컨테이너 /app에 매핑
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

  # 3. 실시간 AI 워커 (STT, LLM 꼬리질문 전담)
  rt_worker:
    build: .
    container_name: worker_realtime
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    env_file: .env
    environment:
      - PHOENIX_COLLECTOR_ENDPOINT=http://phoenix:6006
    command: celery -A tasks worker -Q realtime_queue --concurrency=1 --loglevel=info
    depends_on:
      - phoenix
    volumes:
      - Z:\:/shared_data # 윈도우 Z드라이브를 컨테이너 내 /shared_data로 매핑

  # 4. LLM 서버 (Ollama)
  ollama:
    image: ollama/ollama
    container_name: ollama_server
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 5. Arize Phoenix 추가 (Observability)
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: arize_phoenix
    ports:
      - "6006:6006" # Phoenix UI 및 데이터 수집 포트
    restart: always