# 서버 구성

## 서버 사양

A : 192.168.40.61

B : 192.168.40.62

C : 192.168.40.54

## 서버사양

3개의 서버가 모두 동일 사양

프로세서 : AMD Ryzen 5 PRO 4650G with Radeon Graphics   3.70 GHz
설치된 : RAM 32.0GB
저장소 : 466 GB SSD Samsung SSD 970 EVO 500GB
그래픽 카드 : NVIDIA GeForce GTX 1660 SUPER (6 GB)
시스템 종류 : 64비트 운영 체제, x64 기반 프로세서

# ai 구성 추천

동일한 사양의 서버 3대(**$192.168.40.61, 62, 54$**)를 활용하여 **GTX 1660 SUPER(6GB VRAM)**의 한계를 극복하고, 요청하신 모든 기능(STT, TTS, 시각 지능, LLM 분석, 배치)을 안정적으로 수행할 수 있는 두 가지 아키텍처를 제안합니다.

---

## 추천 1: 역할 기반 계층형 구성 (안정성 및 보안 중심)

이 구성은 **웹 서비스, AI 모델, 데이터 저장소**를 완전히 분리하여 자원 간 간섭을 차단합니다. 관리가 용이하고 특정 서버 장애 시 원인 파악이 빠릅니다.

### 1) 서버별 배치 구조

| **서버**    | **역할**         | **배치 서비스**                        | **자원 활용 포인트**                         |
| ----------------- | ---------------------- | -------------------------------------------- | -------------------------------------------------- |
| **A (.61)** | **Web & Queue**  | FastAPI, Redis, Celery Beat, Dashboard API   | 사용자 접속 및 메시지 브로커 전담                  |
| **B (.62)** | **AI Engine**    | STT, TTS, 얼굴 인식/표정 감지, LLM(꼬리질문) | **GPU(6GB) 전용 사용** , 모든 모델 추론 전담 |
| **C (.54)** | **Data & Batch** | PostgreSQL(pgvector), Oracle, 배치 프로그램  | DB 트랜잭션 및 대량 데이터 수집(Batch) 전담        |

### 2) 핵심 Docker Compose 설정 (서버 B: AI Engine 예시)

서버 B는 GPU 자원을 최대한 활용하도록 설정해야 합니다.

**YAML**

```
# Server B (192.168.40.62) docker-compose.yml
version: '3.8'
services:
  ai_worker:
    build: ./worker
    container_name: interview_ai_worker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - REDIS_URL=redis://192.168.40.61:6379/0
      - DB_URL=postgresql://admin:pass@192.168.40.54:5432/interview
    command: celery -A tasks worker --loglevel=info -Q ai_tasks --concurrency=1
```

---

## 추천 2: 부하 분산 클러스터형 구성 (처리량 및 성능 중심)

가장 부하가 큰 **AI 추론(GPU)**을 두 대의 서버에 나누어 배치하여, 실시간 면접 인원 수용량을 극대화하는 구성입니다.

### 1) 서버별 배치 구조

| **서버**    | **역할**              | **배치 서비스**                   | **자원 활용 포인트**                |
| ----------------- | --------------------------- | --------------------------------------- | ----------------------------------------- |
| **A (.61)** | **Real-time AI Node** | FastAPI, STT, LLM(실시간 대화), Redis   | 실시간 면접 대화 및 사용자 접점 담당      |
| **B (.62)** | **Vision & Analysis** | 얼굴 인식, 표정 감지, 이력서 분석, 배치 | 시각 정보 분석 및 무거운 비동기 분석 담당 |
| **C (.54)** | **Central Data**      | PostgreSQL, Oracle, Dashboard Backend   | 모든 서비스의 데이터를 통합 관리          |

### 2) 특징 및 장점

* **자원 최적화** : 서버 A는 실시간성(음성/대화)에 집중하고, 서버 B는 분석성(얼굴/이력서/배치)에 집중하여 GPU 부하를 분산합니다.
* **배치 안정성** : 서버 B에서 돌아가는 배치 프로그램이 데이터를 수집하여 서버 C의 Oracle/Postgres에 적재하므로 데이터 가용성이 높습니다.

---

## 주요 기능 구현 및 호환성 가이드

### ① 모델 및 라이브러리 (requirements.txt)

6GB VRAM 환경에서 모든 모델을 구동하기 위한 핵심 조합입니다.

**Plaintext**

```
# AI Frameworks
torch==2.3.1+cu121
faster-whisper==1.0.3  # STT
edge-tts==6.1.12       # TTS (CPU 사용 권장)
opencv-python          # 얼굴 인식
deepface               # 표정 감지 (경량화 모델 사용)

# LLM & Vector DB
langchain==0.2.14
ollama                 # Llama-3.1 8B (4-bit 양자화)
psycopg2-binary        # PostgreSQL
cx_Oracle              # Oracle 연동

# Async Task
celery==5.4.0
redis==5.0.8
```

### ② 기능별 상세 가이드

* **얼굴 및 표정 감지** : `DeepFace` 또는 `MediaPipe`를 사용합니다. 실시간 점수 반영을 위해 1초당 1~2프레임만 분석하여 GPU 부하를 줄입니다.
* **이력서 분석/첨삭** : PDF 추출은 `PyMuPDF`를 사용하고, LLM에 넘겨 JSON으로 구조화합니다. (서버 C의 배치 또는 서버 B의 워커에서 수행)
* **면접 결과 대시보드** : PostgreSQL의 `pgvector`를 활용하여 분야별 추이(유사도 점수)를 계산하고, FastAPI가 이를 그래프용 데이터로 가공하여 전달합니다.
* **배치 프로그램** : `Celery Beat`를 사용하여 매일 새벽 전일 면접 내용을 요약하고, 회사 정보 및 채용 정보를 크롤링하여 Oracle DB에 적재합니다.

---

### 💡 권장 환경 설정 (Common)

1. **VRAM 공유** : LLM은 **Ollama**를 통해 백그라운드에서 구동하여 시스템 RAM과 VRAM을 유동적으로 사용하게 하십시오.
2. **데이터베이스 분리** : Oracle은 엔터프라이즈 데이터(회사 정보, 회원)용으로, PostgreSQL은 AI 분석 데이터(벡터, 로그)용으로 이원화하여 사용하십시오.
3. **네트워크** : 서버 간 데이터 전송(음성/영상)량이 많으므로 1Gbps 이상의 내부망 연결이 필수입니다.

## docker 구성

부하 분산 클러스터형 구성은 **실시간 대화(서버 A)**와 **정밀 분석 및 배치(서버 B)**로 GPU 부하를 나누어 전체 시스템의 처리량을 극대화하는 방식입니다.

모든 서버는 동일한 `requirements.txt`를 공유하는 파이썬 환경을 기반으로 하며, 각 서버의 IP에 맞춰 서로를 참조하도록 설정합니다.

---

### 0. 공통 환경 설정 (.env)

모든 서버의 프로젝트 루트 폴더에 아래 내용을 담은 `.env` 파일을 생성하세요.

**Plaintext**

```
# Server IPs
IP_A=192.168.40.61
IP_B=192.168.40.62
IP_C=192.168.40.54

# DB Settings
POSTGRES_USER=admin
POSTGRES_PASSWORD=interview_pass
POSTGRES_DB=interview_db
ORACLE_PASSWORD=oracle_pass

# Redis & Celery
REDIS_URL=redis://192.168.40.61:6379/0
CELERY_BROKER_URL=redis://192.168.40.61:6379/0
CELERY_RESULT_BACKEND=redis://192.168.40.61:6379/0
```

---

### 1. 서버 A (192.168.40.61): 실시간 대화 및 인터페이스 노드

사용자 접속을 처리하고, 실시간 음성 인식(STT)과 대화 생성(LLM)에 GPU를 집중합니다.

**YAML**

```
# Server A: docker-compose.yml
version: '3.8'

services:
  # 1. 메시지 브로커 (중앙 집중형)
  redis:
    image: redis:7.2-alpine
    container_name: central_redis
    ports:
      - "6379:6379"
    restart: always

  # 2. 메인 웹 서버 (FastAPI)
  web:
    build: .
    container_name: interview_api
    ports:
      - "8000:8000"
    env_file: .env
    depends_on:
      - redis

  # 3. 실시간 AI 워커 (STT, LLM 꼬리질문 전담)
  rt_worker:
    build: .
    container_name: worker_realtime
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    env_file: .env
    command: celery -A tasks worker -Q realtime_queue --concurrency=1 --loglevel=info

  # 4. LLM 서버 (Ollama 활용)
  ollama:
    image: ollama/ollama
    container_name: ollama_server
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

### 2. 서버 B (192.168.40.62): 시각 분석 및 배치 작업 노드

얼굴/표정 인식과 이력서 분석, 그리고 주기적인 데이터 적재(Batch)에 GPU를 사용합니다.

**YAML**

```
# Server B: docker-compose.yml
version: '3.8'

services:
  # 1. 정밀 분석 워커 (얼굴인식, 이력서 첨삭, 결과 리포트 생성)
  analysis_worker:
    build: .
    container_name: worker_analysis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    env_file: .env
    command: celery -A tasks worker -Q analysis_queue --concurrency=1 --loglevel=info

  # 2. 배치 스케줄러 (회사/취업 정보 수집, 전일 내용 정리)
  celery_beat:
    build: .
    container_name: interview_beat
    env_file: .env
    command: celery -A tasks beat --loglevel=info

  # 3. 배치 전용 워커 (데이터 적재 전용)
  batch_worker:
    build: .
    container_name: worker_batch
    env_file: .env
    command: celery -A tasks worker -Q batch_queue --loglevel=info
```

---

### 3. 서버 C (192.168.40.54): 중앙 데이터 센터 노드

모든 데이터를 저장하고 통계를 처리하는 고성능 DB 노드입니다.

**YAML**

```
# Server C: docker-compose.yml
version: '3.8'

services:
  # 1. 관계형 및 벡터 DB (PostgreSQL + pgvector)
  postgres:
    image: pgvector/pgvector:pg16
    container_name: vector_db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: always

  # 2. 엔터프라이즈 DB (Oracle XE)
  oracle:
    image: gvenzl/oracle-xe:latest
    container_name: enterprise_db
    ports:
      - "1521:1521"
    environment:
      ORACLE_PASSWORD: ${ORACLE_PASSWORD}
    volumes:
      - oracle_data:/opt/oracle/oradata
    restart: always

volumes:
  pg_data:
  oracle_data:
```

---

### 4. 필수 라이브러리 (requirements.txt)

**Plaintext**

```
fastapi
uvicorn
celery
redis
sqlalchemy
psycopg2-binary
cx_Oracle
python-dotenv
# AI Models
faster-whisper
edge-tts
opencv-python
deepface
ollama
langchain
langchain-community
# File Processing
PyMuPDF
python-docx
# Analytics
pandas
matplotlib
```

---

### 💡 구성 요약 및 운영 팁

1. **네트워크 흐름** : 서버 A의 `FastAPI`가 요청을 받으면 `Redis`(.61)를 통해 작업을 분배합니다. 실시간 음성/대화는 서버 A가, 비전/서류 분석은 서버 B가 가로채어 처리합니다. 최종 데이터는 서버 C로 모입니다.
2. **GPU 충돌 방지** : 각 워커의 `--concurrency=1` 설정은 6GB VRAM에서 여러 모델이 엉켜 죽는 것을 방지합니다. 작업을 하나씩 차례대로 완벽하게 처리합니다.
3. **배치 시스템** : `celery_beat`가 서버 B에서 작동하며, 매일 정해진 시간에 크롤러와 요약 프로그램을 실행하여 서버 C의 Oracle DB를 업데이트합니다.
4. **확장성** : 추후 사용자가 늘어나면 서버 A와 B의 역할을 하는 서버만 추가하여 리스트에 등록하면 즉시 성능이 확장됩니다.

이제 각 서버의 폴더에 해당 파일을 배치하고 `docker-compose up -d` 명령어로 서비스를 시작할 수 있습니다. **첫 실행 시 Oracle DB의 초기 설정 시간이 다소 걸릴 수 있으니 참고하세요.**

혹시 **서버 간 파일(음성/이력서)을 공유하기 위한 공유 저장소(NFS 등) 설정**도 함께 필요하신가요? Would you like me to ... 도와드릴까요?
