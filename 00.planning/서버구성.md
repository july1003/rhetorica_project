# 서버 구성

## 서버 사양

A : 192.168.40.61

B : 192.168.40.62

C : 192.168.40.54

## 서버사양

3개의 서버가 모두 동일 사양

프로세서 : AMD Ryzen 5 PRO 4650G with Radeon Graphics   3.70 GHz
설치된 : RAM 32.0GB
저장소 : 466 GB SSD Samsung SSD 970 EVO 500GB
그래픽 카드 : NVIDIA GeForce GTX 1660 SUPER (6 GB)
시스템 종류 : 64비트 운영 체제, x64 기반 프로세서


## 서버 이름

### ** 아리스토텔레스의 수사학: 설득의 3요소**

면접이라는 과정이 결국 '나를 증명하고 설득하는 과정'임을 은유했습니다.

* **A 서버 (대화) →Logos(로고스)**

  * **의미:** **말, 언어, 논리**를 뜻합니다.
  * **이유:** 실시간으로 논리적인 대화가 오가는 인터페이스 부분입니다. 면접의 '내용'과 '흐름'을 담당합니다.
* **B 서버 (태도) →Pathos(파토스)**

  * **의미:** **감정, 공감, 정서적 호소**를 뜻합니다.
  * **이유:** 텍스트 너머의 비언어적 요소(표정, 분위기)를 읽어내고 분석하는 감성적/직관적 분석 영역입니다.
* **C 서버 (근거) →Ethos(에토스)**

  * **의미:** **신뢰성, 인격, 고유한 성품**을 뜻합니다.
  * **이유:** 변하지 않는 데이터와 신뢰할 수 있는 기록들이 모여 시스템의 권위와 신뢰(Source of Truth)를 형성합니다.



# ai 구성 추천

동일한 사양의 서버 3대(**$192.168.40.61, 62, 54$**)를 활용하여 **GTX 1660 SUPER(6GB VRAM)**의 한계를 극복하고, 요청하신 모든 기능(STT, TTS, 시각 지능, LLM 분석, 배치)을 안정적으로 수행할 수 있는 두 가지 아키텍처를 제안합니다.

---

## 추천 1: 역할 기반 계층형 구성 (안정성 및 보안 중심)

이 구성은 **웹 서비스, AI 모델, 데이터 저장소**를 완전히 분리하여 자원 간 간섭을 차단합니다. 관리가 용이하고 특정 서버 장애 시 원인 파악이 빠릅니다.

### 1) 서버별 배치 구조

| **서버**    | **역할**         | **배치 서비스**                        | **자원 활용 포인트**                         |
| ----------------- | ---------------------- | -------------------------------------------- | -------------------------------------------------- |
| **A (.61)** | **Web & Queue**  | FastAPI, Redis, Celery Beat, Dashboard API   | 사용자 접속 및 메시지 브로커 전담                  |
| **B (.62)** | **AI Engine**    | STT, TTS, 얼굴 인식/표정 감지, LLM(꼬리질문) | **GPU(6GB) 전용 사용** , 모든 모델 추론 전담 |
| **C (.54)** | **Data & Batch** | PostgreSQL(pgvector), Oracle, 배치 프로그램  | DB 트랜잭션 및 대량 데이터 수집(Batch) 전담        |

### 2) 핵심 Docker Compose 설정 (서버 B: AI Engine 예시)

서버 B는 GPU 자원을 최대한 활용하도록 설정해야 합니다.

**YAML**

```
# Server B (192.168.40.62) docker-compose.yml
version: '3.8'
services:
  ai_worker:
    build: ./worker
    container_name: interview_ai_worker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - REDIS_URL=redis://192.168.40.61:6379/0
      - DB_URL=postgresql://admin:pass@192.168.40.54:5432/interview
    command: celery -A tasks worker --loglevel=info -Q ai_tasks --concurrency=1
```

---

## 추천 2: 부하 분산 클러스터형 구성 (처리량 및 성능 중심)

가장 부하가 큰 **AI 추론(GPU)**을 두 대의 서버에 나누어 배치하여, 실시간 면접 인원 수용량을 극대화하는 구성입니다.

### 1) 서버별 배치 구조

| **서버**    | **역할**              | **배치 서비스**                                     | **자원 활용 포인트**                |
| ----------------- | --------------------------- | --------------------------------------------------------- | ----------------------------------------- |
| **A (.61)** | **Real-time AI Node** | FastAPI, STT, LLM(실시간 대화), Redis                     | 실시간 면접 대화 및 사용자 접점 담당      |
| **B (.62)** | **Vision & Analysis** | 얼굴 인식, 표정 감지, 이력서 분석, 배치                   | 시각 정보 분석 및 무거운 비동기 분석 담당 |
| **C (.54)** | **Central Data**      | PostgreSQL, Oracle, Dashboard Backend, 임베딩모델, ㅓ배치 | 모든 서비스의 데이터를 통합 관리          |

### 2) 특징 및 장점

* **자원 최적화** : 서버 A는 실시간성(음성/대화)에 집중하고, 서버 B는 분석성(얼굴/이력서/배치)에 집중하여 GPU 부하를 분산합니다.
* **배치 안정성** : 서버 B에서 돌아가는 배치 프로그램이 데이터를 수집하여 서버 C의 Oracle/Postgres에 적재하므로 데이터 가용성이 높습니다.

---

## 주요 기능 구현 및 호환성 가이드

### ① 모델 및 라이브러리 (requirements.txt)

6GB VRAM 환경에서 모든 모델을 구동하기 위한 핵심 조합입니다.

**Plaintext**

```
# AI Frameworks
torch==2.3.1+cu121
faster-whisper==1.0.3  # STT
edge-tts==6.1.12       # TTS (CPU 사용 권장)
opencv-python          # 얼굴 인식
deepface               # 표정 감지 (경량화 모델 사용)

# LLM & Vector DB
langchain==0.2.14
ollama                 # Llama-3.1 8B (4-bit 양자화)
psycopg2-binary        # PostgreSQL
cx_Oracle              # Oracle 연동

# Async Task
celery==5.4.0
redis==5.0.8
```

### ② 기능별 상세 가이드

* **얼굴 및 표정 감지** : `DeepFace` 또는 `MediaPipe`를 사용합니다. 실시간 점수 반영을 위해 1초당 1~2프레임만 분석하여 GPU 부하를 줄입니다.
* **이력서 분석/첨삭** : PDF 추출은 `PyMuPDF`를 사용하고, LLM에 넘겨 JSON으로 구조화합니다. (서버 C의 배치 또는 서버 B의 워커에서 수행)
* **면접 결과 대시보드** : PostgreSQL의 `pgvector`를 활용하여 분야별 추이(유사도 점수)를 계산하고, FastAPI가 이를 그래프용 데이터로 가공하여 전달합니다.
* **배치 프로그램** : `Celery Beat`를 사용하여 매일 새벽 전일 면접 내용을 요약하고, 회사 정보 및 채용 정보를 크롤링하여 Oracle DB에 적재합니다.

---

### 💡 권장 환경 설정 (Common)

1. **VRAM 공유** : LLM은 **Ollama**를 통해 백그라운드에서 구동하여 시스템 RAM과 VRAM을 유동적으로 사용하게 하십시오.
2. **데이터베이스 분리** : Oracle은 엔터프라이즈 데이터(회사 정보, 회원)용으로, PostgreSQL은 AI 분석 데이터(벡터, 로그)용으로 이원화하여 사용하십시오.
3. **네트워크** : 서버 간 데이터 전송(음성/영상)량이 많으므로 1Gbps 이상의 내부망 연결이 필수입니다.

## docker 구성

부하 분산 클러스터형 구성은 **실시간 대화(서버 A)**와 **정밀 분석 및 배치(서버 B)**로 GPU 부하를 나누어 전체 시스템의 처리량을 극대화하는 방식입니다.

모든 서버는 동일한 `requirements.txt`를 공유하는 파이썬 환경을 기반으로 하며, 각 서버의 IP에 맞춰 서로를 참조하도록 설정합니다.

---

### 0. 공통 환경 설정 (.env)

모든 서버의 프로젝트 루트 폴더에 아래 내용을 담은 `.env` 파일을 생성하세요.

**Plaintext**

```
# Server IPs
IP_A=192.168.40.61
IP_B=192.168.40.62
IP_C=192.168.40.54

# DB Settings
POSTGRES_USER=admin
POSTGRES_PASSWORD=interview_pass
POSTGRES_DB=interview_db
ORACLE_PASSWORD=oracle_pass

# Redis & Celery
REDIS_URL=redis://192.168.40.61:6379/0
CELERY_BROKER_URL=redis://192.168.40.61:6379/0
CELERY_RESULT_BACKEND=redis://192.168.40.61:6379/0
```

---

### 1. 서버 A (192.168.40.61): 실시간 대화 및 인터페이스 노드

사용자 접속을 처리하고, 실시간 음성 인식(STT)과 대화 생성(LLM)에 GPU를 집중합니다.

**YAML**

```
# Server A: docker-compose.yml
version: '3.8'

services:
  # 1. 메시지 브로커 (중앙 집중형)
  redis:
    image: redis:7.2-alpine
    container_name: central_redis
    ports:
      - "6379:6379"
    restart: always

  # 2. 메인 웹 서버 (FastAPI)
  web:
    build: .
    container_name: interview_api
    ports:
      - "8000:8000"
    env_file: .env
    depends_on:
      - redis

  # 3. 실시간 AI 워커 (STT, LLM 꼬리질문 전담)
  rt_worker:
    build: .
    container_name: worker_realtime
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    env_file: .env
    command: celery -A tasks worker -Q realtime_queue --concurrency=1 --loglevel=info

  # 4. LLM 서버 (Ollama 활용)
  ollama:
    image: ollama/ollama
    container_name: ollama_server
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

### 2. 서버 B (192.168.40.62): 시각 분석 및 배치 작업 노드

얼굴/표정 인식과 이력서 분석, 그리고 주기적인 데이터 적재(Batch)에 GPU를 사용합니다.

**YAML**

```
# Server B: docker-compose.yml
version: '3.8'

services:
  # 1. 정밀 분석 워커 (얼굴인식, 이력서 첨삭, 결과 리포트 생성)
  analysis_worker:
    build: .
    container_name: worker_analysis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    env_file: .env
    command: celery -A tasks worker -Q analysis_queue --concurrency=1 --loglevel=info

  # 2. 배치 스케줄러 (회사/취업 정보 수집, 전일 내용 정리)
  celery_beat:
    build: .
    container_name: interview_beat
    env_file: .env
    command: celery -A tasks beat --loglevel=info

  # 3. 배치 전용 워커 (데이터 적재 전용)
  batch_worker:
    build: .
    container_name: worker_batch
    env_file: .env
    command: celery -A tasks worker -Q batch_queue --loglevel=info
```

---

### 3. 서버 C (192.168.40.54): 중앙 데이터 센터 노드

모든 데이터를 저장하고 통계를 처리하는 고성능 DB 노드입니다.

**YAML**

```
# Server C: docker-compose.yml
version: '3.8'

services:
  # 1. 관계형 및 벡터 DB (PostgreSQL + pgvector)
  postgres:
    image: pgvector/pgvector:pg16
    container_name: vector_db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: always

  # 2. 엔터프라이즈 DB (Oracle XE)
  oracle:
    image: gvenzl/oracle-xe:latest
    container_name: enterprise_db
    ports:
      - "1521:1521"
    environment:
      ORACLE_PASSWORD: ${ORACLE_PASSWORD}
    volumes:
      - oracle_data:/opt/oracle/oradata
    restart: always

volumes:
  pg_data:
  oracle_data:
```

---

### 4. 필수 라이브러리 (requirements.txt)

**Plaintext**

```
fastapi
uvicorn
celery
redis
sqlalchemy
psycopg2-binary
cx_Oracle
python-dotenv
# AI Models
faster-whisper
edge-tts
opencv-python
deepface
ollama
langchain
langchain-community
# File Processing
PyMuPDF
python-docx
# Analytics
pandas
matplotlib
```

---

### 💡 구성 요약 및 운영 팁

1. **네트워크 흐름** : 서버 A의 `FastAPI`가 요청을 받으면 `Redis`(.61)를 통해 작업을 분배합니다. 실시간 음성/대화는 서버 A가, 비전/서류 분석은 서버 B가 가로채어 처리합니다. 최종 데이터는 서버 C로 모입니다.
2. **GPU 충돌 방지** : 각 워커의 `--concurrency=1` 설정은 6GB VRAM에서 여러 모델이 엉켜 죽는 것을 방지합니다. 작업을 하나씩 차례대로 완벽하게 처리합니다.
3. **배치 시스템** : `celery_beat`가 서버 B에서 작동하며, 매일 정해진 시간에 크롤러와 요약 프로그램을 실행하여 서버 C의 Oracle DB를 업데이트합니다.
4. **확장성** : 추후 사용자가 늘어나면 서버 A와 B의 역할을 하는 서버만 추가하여 리스트에 등록하면 즉시 성능이 확장됩니다.

이제 각 서버의 폴더에 해당 파일을 배치하고 `docker-compose up -d` 명령어로 서비스를 시작할 수 있습니다. **첫 실행 시 Oracle DB의 초기 설정 시간이 다소 걸릴 수 있으니 참고하세요.**

혹시 **서버 간 파일(음성/이력서)을 공유하기 위한 공유 저장소(NFS 등) 설정**도 함께 필요하신가요? Would you like me to ... 도와드릴까요?

# Dockerfile

이전에 작성해 드린 `docker-compose.yml` 파일에서 `build: .` 이라는 설정을 보셨을 겁니다. 이 설정은 현재 폴더에 있는 `Dockerfile`을 읽어서 **우리 시스템에 필요한 모든 라이브러리(STT, 표정 인식, DB 접속 도구 등)가 설치된 "나만의 환경(Image)"**을 만들라는 뜻입니다.

특히 **GTX 1660 SUPER(GPU)**를 사용하고, **OpenCV(얼굴 인식)**와 **Oracle/PostgreSQL**에 접속해야 하므로, 일반적인 파이썬 이미지가 아닌 **GPU 지원 기능과 시스템 패키지가 포함된 Dockerfile**이 꼭 필요합니다.

---

## 1. AI 모의 면접 시스템 통합 Dockerfile

이 파일 하나로 서버 A의 웹 서버와 서버 B의 AI 워커, 배치 프로그램 모두를 구동할 수 있도록 설계했습니다.

**Dockerfile**

```
# 1. GPU 지원 및 파이썬 환경을 위한 NVIDIA CUDA 베이스 이미지 사용
# 윈도우 Docker Desktop(WSL2) 환경에서 GPU를 원활히 쓰기 위해 최적화된 버전입니다.
FROM nvidia/cuda:12.1.0-base-ubuntu22.04

# 2. 파이썬 및 필수 시스템 패키지 설치
# OpenCV(얼굴인식), PostgreSQL, Oracle 클라이언트 설치를 위한 설정입니다.
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libpq-dev \
    libaio1 \
    wget \
    unzip \
    && rm -rf /var/lib/apt/lists/*

# 3. 작업 디렉토리 설정
WORKDIR /app

# 4. 파이썬 패키지 설치
# 이전에 추천드린 requirements.txt 파일을 복사하여 설치합니다.
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt

# 5. 소스 코드 복사
COPY . .

# 6. 환경 변수 설정
# 파이썬 출력을 실시간으로 확인하기 위한 설정입니다.
ENV PYTHONUNBUFFERED=1

# 7. 실행 (docker-compose의 command에서 덮어쓰므로 여기서는 기본값만 설정)
CMD ["python3", "main.py"]
```

---

## 2. 왜 이 Dockerfile이 중요한가요?

* **GPU 가속 (NVIDIA CUDA)** : `nvidia/cuda` 이미지를 기반으로 해야만 워커 서버에서 **얼굴 인식(DeepFace)**이나 **음성 인식(Faster-Whisper)** 시 1660 SUPER의 GPU 파워를 제대로 끌어다 쓸 수 있습니다.
* **시각 지능 지원 (libgl1)** : OpenCV나 얼굴 인식 라이브러리는 윈도우 호스트와 달리 리눅스 컨테이너 내부에서는 특정 그래픽 라이브러리가 없으면 에러가 납니다. 이를 미연에 방지하기 위해 `libgl1-mesa-glx`를 포함했습니다.
* **복합 DB 접속** : Oracle과 PostgreSQL을 동시에 사용하시므로, 각 DB 드라이버가 정상 작동하기 위한 시스템 라이브러리(`libpq-dev`, `libaio1`)를 미리 심어두었습니다.

---

## 3. 윈도우 환경에서 실행 시 주의사항

1. **파일명** : 파일 이름은 반드시 확장자 없이 `Dockerfile`로 저장해야 합니다.
2. **위치** : `docker-compose.yml` 파일과 같은 폴더에 있어야 합니다.
3. **빌드 명령어** : 모든 파일을 준비한 후, 윈도우 파워쉘(PowerShell)에서 아래 명령어를 입력하면 빌드가 시작됩니다.
   **PowerShell**

```
   docker-compose build
```

## 서버C Dockerfile 설정

서버 C는 시스템의 **데이터 심장부**입니다. 여기에는 **PostgreSQL(pgvector)**과 **Oracle XE** 같은 데이터베이스가 올라가며, 추가로 **배치(Batch) 프로그램**이 돌아가게 됩니다.

중요한 점은 **데이터베이스(DB)** 자체는 이미 잘 만들어진 **공식 이미지**를 가져다 쓰기 때문에 별도의 Dockerfile이 필요 없지만, **배치 프로그램**은 우리가 짠 코드를 실행해야 하므로 **전용 Dockerfile**이 필요합니다.

---

### 1. 서버 C의 역할 구분

* **DB 서비스 (PostgreSQL, Oracle)** : `docker-compose.yml`에서 공식 이미지를 설정하여 즉시 실행합니다. (Dockerfile 불필요)
* **배치 서비스 (Batch App)** : 회사 정보 크롤링, 취업 정보 적재, 전일 면접 요약 등을 수행하는 파이썬 코드를 실행하기 위한 **커스텀 Dockerfile**이 필요합니다.

---

### 2. 서버 C 전용 Batch Dockerfile (Dockerfile.batch)

서버 C는 DB 연산에 RAM(32GB)을 많이 써야 하므로, 배치용 Dockerfile은 서버 A, B보다 조금 더 가볍게 구성하는 것이 좋습니다. 하지만 Oracle과 PostgreSQL 접속 라이브러리는 반드시 포함되어야 합니다.

**Dockerfile**

```
# 1. 파이썬 3.10 슬림 베이스 이미지 (서버 C는 DB 부하를 고려해 가벼운 이미지 권장)
FROM python:3.10-slim

# 2. 필수 시스템 패키지 설치
# Oracle용 libaio1과 PostgreSQL용 libpq-dev가 핵심입니다.
RUN apt-get update && apt-get install -y \
    libpq-dev \
    libaio1 \
    wget \
    unzip \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 3. Oracle Instant Client 설치 (Oracle DB 접속에 필수)
WORKDIR /opt/oracle
RUN wget https://download.oracle.com/otn_software/linux/instantclient/instantclient-basic-linuxx64.el9.zip && \
    unzip *.zip && rm -f *.zip
ENV LD_LIBRARY_PATH=/opt/oracle/instantclient_19_25:$LD_LIBRARY_PATH

# 4. 작업 디렉토리 설정
WORKDIR /app

# 5. 파이썬 패키지 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 6. 소스 코드 복사
COPY . .

# 7. 실행 환경 설정
ENV PYTHONUNBUFFERED=1

# 배치 프로그램 실행 파일 지정 (예: batch_main.py)
CMD ["python", "batch_main.py"]
```

---

### 3. 서버 C의 `docker-compose.yml` 최종 구조

서버 C에서는 위에서 만든 `Dockerfile.batch`를 사용하여 배치 서비스를 띄웁니다.

**YAML**

```
# Server C (192.168.40.54) docker-compose.yml
version: '3.8'

services:
  # [DB 1] 벡터 검색용 PostgreSQL
  postgres:
    image: pgvector/pgvector:pg16
    container_name: vector_db
    ports:
      - "5432:5432"
    env_file: .env
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: always

  # [DB 2] 엔터프라이즈용 Oracle
  oracle:
    image: gvenzl/oracle-xe:latest
    container_name: enterprise_db
    ports:
      - "1521:1521"
    env_file: .env
    volumes:
      - oracle_data:/opt/oracle/oradata
    restart: always

  # [Batch] 주기적 데이터 처리 프로그램
  batch_app:
    build:
      context: .
      dockerfile: Dockerfile.batch # 위에서 만든 파일 지정
    container_name: interview_batch
    env_file: .env
    depends_on:
      - postgres
      - oracle
    restart: on-failure

volumes:
  pg_data:
  oracle_data:
```

---

### 4. 윈도우 환경에서의 빌드 및 실행 팁

1. **파일명 구분** : 서버 A, B용 Dockerfile과 서버 C의 배치용 Dockerfile을 구분해서 저장하세요. (예: `Dockerfile.ai`, `Dockerfile.batch`)
2. **Oracle 초기 가동** : Oracle XE 이미지는 처음 실행될 때 데이터베이스 구조를 만드느라 시간이 다소 걸립니다. (최대 3~5분) 이때 배치 프로그램이 접속을 시도하면 에러가 날 수 있으니, 파이썬 코드 내에서 **재시도(Retry) 로직**을 넣는 것이 좋습니다.
3. **메모리 배분** : 32GB RAM 중 8~12GB는 Oracle에, 4~8GB는 PostgreSQL에 할당되도록 설정하면 배치 프로그램이 안정적으로 동작합니다.
